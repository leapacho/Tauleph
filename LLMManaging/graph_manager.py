import os
from groq import Groq
from langchain_groq import ChatGroq 
from langchain_google_genai import ChatGoogleGenerativeAI
from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages 
from langchain_community.utilities import SearxSearchWrapper
from langchain_community.tools.searx_search.tool import SearxSearchResults
from langchain.tools import tool
from langgraph.prebuilt import ToolNode, tools_condition
import sqlite3
from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.checkpoint.memory import MemorySaver
import pickle
import json
from dotenv import load_dotenv
from tauleph_discord_bot import bot 
load_dotenv() #Loads environment variables.

with open(f"model_list.json", "r") as file: 
    model_list=json.load(file) #Loads the model list from the JSON file.
# conn = sqlite3.connect("checkpoints.sqlite", check_same_thread=False)
memory = MemorySaver() #SqliteSaver is a class that intefaces sqlite3.
client = Groq(api_key=os.environ.get("GROQ_API_KEY")) #Groq is a class that allows you to interact with the Groq API.
config = {"configurable": {"thread_id": "1"}} #Config is a dictionary that contains the configuration for the graph. In this case, it contains the thread_id.
searx_search = SearxSearchWrapper(searx_host="http://localhost:32787") #SearxSearchWrapper is a class that allows you to interact with the Searx API.
searx_tool = SearxSearchResults(wrapper=searx_search, num_results=10) #SearxSearchResults is a class that allows you to get search results from Searx.


class State(TypedDict): 
    messages: Annotated[list, add_messages] #Creates the state. The state is a dictionary that contains the messages.

def setup_graph(input_model):
    global config
    graph_builder = StateGraph(State) #StateGraph is a class that creates a graph with the state.
    
    # #Tools.
    # @tool("image_description")
    # def image_description(user_input: str, url: str) -> str:
    #     """

    #     Image Description Tool: Describes an image based on the provided URL.

    #     Args:
    #         user_input (str): The input from the user. e.g: specific parts/details of the image.
    #         url (str): The URL of the image you want to get a description of.

    #     Returns:
    #         str: A description of the image based on the provided URL and user input.
    #     """
    #     return vision_llm_input(user_input, url)
    
    # @tool("audio_transcription")
    # def audio_transcription(context_style: str, audio_url: str, language: str) -> str:
    #     """
        
    #     Audio Transcription Tool: Transcribes an audio based on the provided URL.

    #     Args:
    #         context_style (str):  Provide context or transcription  style. Default to "Transcribe this audio accurately" if none provided.
    #         audio_url (str): URL of the audio you want to get a transcription of.
    #         language (str): Specify the language for transcription. Use ISO 639-1 language codes (e.g. "en" for English, "fr" for French, etc). Leave empty if none provided.
        
    #     Returns:
    #         str: A transcription of the audio based on the provided arguments.
    #     """
    #     return speech_llm_input(context_style, audio_url, language)
    
    @tool("retrieve_recent_messages")
    def query_chat_history() -> list:
        """
            Retrieve Recent Messages Tool: A chat history retrieval tool.Useful for when you need to answer questions about past actions in the chat.No input.Output is a list of the 15 most recent messages
        """
        message_list=bot.history_messages()
        return message_list

    
    # google = ChatGoogleGenerativeAI(model=input_model)
    # # groq = ChatGroq(model=input_model)
    # groq_tools = [image_description, audio_transcription, searx_tool]
    # google_tools = [searx_tool]
    # llm_providers = {"google": [google, google_tools], "groq": [groq, groq_tools]}

    llm = ChatGoogleGenerativeAI(model=input_model)
    tools = [searx_tool, query_chat_history]

    # for provider in llm_providers.keys():
    #     if input_model in model_list[provider]:
    #         llm = llm_providers[provider][0]
    #         tools = llm_providers[provider][1]       
    llm_with_tools = llm.bind_tools(tools)


    def chatbot(state: State):
        return {"messages": [llm_with_tools.invoke(state["messages"])]} #The chatbot function takes the state as input and returns the messages generated by the LLM with tools.
    
    graph_builder.add_node("chatbot", chatbot) #Adds the chatbot node to the graph.
    graph_builder.add_node("tools", ToolNode(tools)) #Adds the tools node to the graph.
    
    graph_builder.add_conditional_edges("chatbot", tools_condition) #Adds conditional edges between the chatbot and tools nodes.
    graph_builder.add_edge("tools", "chatbot") #Adds an edge between the tools and chatbot nodes.
    graph_builder.set_entry_point("chatbot") #Sets the entry point of the graph to the chatbot node.
    runnable = graph_builder.compile(checkpointer=memory) #Compiles the graph with the memory checkpointer.

    return runnable #Returns the runnable graph.

def process_input(graph, config, initial_messages=None):
    """
    Processes the input messages through the graph and returns the last message.
    """

    response = graph.invoke({"messages": initial_messages}, config) if initial_messages else graph.invoke(None, config) 

    return response["messages"][-1].content


    